{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60df9f4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from scipy.special import binom as binom_fun\n",
    "from scipy.special import factorial as sp_factorial\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.integrate import quad\n",
    "\n",
    "import theano\n",
    "import theano.tensor as T\n",
    "from theano.graph.op import Op\n",
    "from theano.graph.basic import Apply\n",
    "from theano.compile.io import In\n",
    "\n",
    "#import quadpy\n",
    "\n",
    "%matplotlib nbagg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7fe29cda",
   "metadata": {},
   "outputs": [],
   "source": [
    "def p_nu(NU,gamma,delta,nu_max):\n",
    "\n",
    "    return gamma / ( nu_max * T.sqrt( -np.pi * T.log( NU / nu_max ) ) ) * \\\n",
    "        T.exp( - delta**2/2.) * ( NU / nu_max )**(gamma**2 - 1) * \\\n",
    "        T.cosh( gamma * delta * T.sqrt( -2 * T.log( NU / nu_max) ) )\n",
    "\n",
    "def poisson_spikes(nu,N,T_total):\n",
    "    return (nu*T_total)**N / T.gamma(N+1) * T.exp(-nu*T_total)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b77b7e12",
   "metadata": {},
   "outputs": [],
   "source": [
    "T_total = 600.#T.dscalar('T')      # measurement time\n",
    "\n",
    "N_AP = T.dvector('N_AP')           # number of action potentials (should be vector)\n",
    "N = T.dscalar('N')\n",
    "\n",
    "nu = T.dscalar('nu')\n",
    "\n",
    "gamma = T.dscalar('gamma')\n",
    "delta = T.dscalar('delta')\n",
    "nu_max = T.dscalar('nu_max')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "9524568d",
   "metadata": {},
   "outputs": [],
   "source": [
    "class integrateOut(Op):\n",
    "    \"\"\"\n",
    "    Integrate out a variable from an expression, computing\n",
    "    the definite integral w.r.t. the variable specified\n",
    "    !!! Only implemented in this for scalars !!!\n",
    "    \"\"\"\n",
    "    \n",
    "    #vectorize = True\n",
    "    \n",
    "    def __init__(self,f,t,vectorize,*args,**kwargs):\n",
    "        super(integrateOut,self).__init__()\n",
    "        self.f = f\n",
    "        self.t = t\n",
    "        self.vectorize = vectorize\n",
    "\n",
    "    def make_node(self,*inputs):\n",
    "        self.fvars=list(inputs)\n",
    "        print(f'[make node]: inputs: {inputs}, fvars:{self.fvars}')\n",
    "        # This will fail when taking the gradient... don't be concerned\n",
    "        try:\n",
    "            self.gradF = T.jacobian(self.f,self.fvars)\n",
    "        except:\n",
    "            self.gradF = None\n",
    "            \n",
    "        if self.vectorize:\n",
    "            return Apply(self,self.fvars,[T.dvector().type()])\n",
    "        else:\n",
    "            return Apply(self,self.fvars,[T.dscalar().type()])\n",
    "\n",
    "    def perform(self,node, inputs, output_storage):       \n",
    "        # create a function to evaluate the integral\n",
    "        \n",
    "        ## integrate the function from 0 to maximum firing rate nu_max\n",
    "        N_AP = inputs[0]\n",
    "        nu_max = inputs[3]\n",
    "        if self.gradF is None:\n",
    "            print(f'[perform (grad)]: inputs: {inputs}, fvars:{self.fvars}')\n",
    "        else:\n",
    "            print(f'[perform (fun)]: inputs: {inputs}, fvars:{self.fvars}')\n",
    "        if self.vectorize:\n",
    "            #N = T.lscalar('N')\n",
    "            #print([self.t]+[N] + self.fvars[1:])\n",
    "            #print(theano.clone(self.f,replace={self.fvars[0]:N}))\n",
    "            #theano.printing.debugprint(self.f)\n",
    "            f = theano.function([self.t]+self.fvars,self.f)\n",
    "            \n",
    "            output = np.zeros_like(N_AP,dtype='float64')\n",
    "            for i,N in enumerate(N_AP):\n",
    "                args = inputs[:]\n",
    "                args[0] = np.array([N])   # necessary to be 1-dim vector to satisfy function-blueprint\n",
    "                print(f'args: {args}')\n",
    "                output[i] = quad(f,0,nu_max,args=tuple(args))[0]\n",
    "            output_storage[0][0] = output\n",
    "        else:\n",
    "            f = theano.function([self.t]+self.fvars,self.f)\n",
    "            output_storage[0][0] = np.array(quad(f,0,nu_max,args=tuple(inputs))[0],dtype='float64')\n",
    "\n",
    "    def grad(self,inputs,output_grads):\n",
    "        nu_max = inputs[3]\n",
    "        \n",
    "        giv = {}\n",
    "        for v,v_new in zip(self.fvars[1:],list(inputs)[1:]):\n",
    "            giv[v] = v_new\n",
    "        print(f'giv: {giv}')\n",
    "        print(self.gradF)\n",
    "        return [T.mean(integrateOut(theano.clone(g,replace=giv),self.t,self.vectorize)(*inputs)*output_grads[0]) \\\n",
    "            for g in self.gradF]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "265fde0c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[make node]: inputs: (N_AP, gamma, delta, nu_max), fvars:[N_AP, gamma, delta, nu_max]\n",
      "[perform (fun)]: inputs: [array([ 0,  3,  5, 10]), array(1.2), array(4.8), array(30.)], fvars:[N_AP, gamma, delta, nu_max]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING (theano.tensor.opt): Optimization Warning: The Op gamma does not provide a C implementation. As well as being potentially slow, this also disables loop fusion.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "args: [array([0]), array(1.2), array(4.8), array(30.)]\n",
      "args: [array([3]), array(1.2), array(4.8), array(30.)]\n",
      "args: [array([5]), array(1.2), array(4.8), array(30.)]\n",
      "args: [array([10]), array(1.2), array(4.8), array(30.)]\n",
      "[perform (fun)]: inputs: [array([ 0,  3,  5, 10]), array(1.2), array(4.8), array(30.)], fvars:[N_AP, gamma, delta, nu_max]\n",
      "args: [array([0]), array(1.2), array(4.8), array(30.)]\n",
      "args: [array([3]), array(1.2), array(4.8), array(30.)]\n",
      "args: [array([5]), array(1.2), array(4.8), array(30.)]\n",
      "args: [array([10]), array(1.2), array(4.8), array(30.)]\n",
      "[1.06234782e-09 3.62980190e-02 2.32467904e-02 1.21495837e-02]\n",
      "giv: {gamma: gamma, delta: delta, nu_max: nu_max}\n",
      "[for{cpu,scan_fn}.0, for{cpu,scan_fn}.1, for{cpu,scan_fn}.2, for{cpu,scan_fn}.3]\n",
      "[make node]: inputs: (N_AP, gamma, delta, nu_max), fvars:[N_AP, gamma, delta, nu_max]\n",
      "[make node]: inputs: (N_AP, gamma, delta, nu_max), fvars:[N_AP, gamma, delta, nu_max]\n",
      "[make node]: inputs: (N_AP, gamma, delta, nu_max), fvars:[N_AP, gamma, delta, nu_max]\n",
      "[make node]: inputs: (N_AP, gamma, delta, nu_max), fvars:[N_AP, gamma, delta, nu_max]\n",
      "giv: {gamma: gamma, delta: delta, nu_max: nu_max}\n",
      "[for{cpu,scan_fn}.0, for{cpu,scan_fn}.1, for{cpu,scan_fn}.2, for{cpu,scan_fn}.3]\n",
      "[make node]: inputs: (N_AP, gamma, delta, nu_max), fvars:[N_AP, gamma, delta, nu_max]\n",
      "[make node]: inputs: (N_AP, gamma, delta, nu_max), fvars:[N_AP, gamma, delta, nu_max]\n",
      "[make node]: inputs: (N_AP, gamma, delta, nu_max), fvars:[N_AP, gamma, delta, nu_max]\n",
      "[make node]: inputs: (N_AP, gamma, delta, nu_max), fvars:[N_AP, gamma, delta, nu_max]\n"
     ]
    }
   ],
   "source": [
    "theano.config.optimizer = 'fast_run'\n",
    "theano.config.exception_verbosity = 'high'\n",
    "theano.config.on_unused_input = 'warn'\n",
    "theano.config.mode = 'FAST_RUN'\n",
    "\n",
    "p_N_AP = integrateOut(p_nu(nu,gamma,delta,nu_max)*poisson_spikes(nu,N_AP,T_total),nu,vectorize=True)(N_AP,gamma,delta,nu_max)\n",
    "func_p = theano.function([N_AP,gamma,delta,nu_max],p_N_AP)\n",
    "func_vals = func_p([0,3,5,10],1.2,4.8,30.)\n",
    "print(func_vals)\n",
    "\n",
    "pGrad = T.jacobian(p_N_AP,[gamma,delta,nu_max],consider_constant=[N_AP])\n",
    "funcGrad = theano.function([N_AP,gamma,delta,nu_max],pGrad,mode='DebugMode',on_unused_input='warn')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "195ada25",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "grad_vals = funcGrad([0,3,5],1.2,5.8,30.)\n",
    "print(grad_vals)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "2242fdfb",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1.06234782e-09 3.62980190e-02 2.32467904e-02 1.21495837e-02]\n"
     ]
    }
   ],
   "source": [
    "theano.config.optimizer = 'fast_run'\n",
    "\n",
    "p_N_AP_arr, updates = theano.scan(\n",
    "    fn = lambda N, gamma, delta, nu_max : integrateOut(p_nu(nu,gamma,delta,nu_max)*poisson_spikes(nu,N,T_total),nu,vectorize=False)(N,gamma,delta,nu_max), \n",
    "    sequences=[N_AP],\n",
    "    non_sequences=[gamma,delta,nu_max],\n",
    ")\n",
    "func_p = theano.function([N_AP,gamma,delta,nu_max],p_N_AP_arr)\n",
    "func_vals = func_p([0.,3.,5.,10.],1.2,4.8,30.)\n",
    "print(func_vals)\n",
    "\n",
    "pGrad = T.jacobian(p_N_AP_arr,[gamma,delta,nu_max],consider_constant=[N_AP])\n",
    "funcGrad = theano.function([N_AP,gamma,delta,nu_max],pGrad,mode='FAST_RUN')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "c2f57636",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[array([2.62735034e-09, 1.10484408e-01, 6.93019521e-02]), array([-6.10352823e-10, -2.07417269e-02, -1.38951575e-02]), array([5.51702792e-12, 6.86296925e-09, 1.05980551e-04])]\n"
     ]
    }
   ],
   "source": [
    "grad_vals = funcGrad([0.,3.,5.],1.2,5.8,30.)\n",
    "print(grad_vals)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "6cd47d30",
   "metadata": {},
   "outputs": [],
   "source": [
    "rng = np.random.RandomState(42)\n",
    "def p_N_AP_fun(N_AP,gamma,delta,nu_max):\n",
    "    #p_N_AP = integrateOut(p_nu(nu,gamma,delta,nu_max)*poisson_spikes(nu,N,T_total),nu)(gamma,delta,nu_max,N)\n",
    "    \n",
    "    p_N_AP_arr, updates = theano.scan(\n",
    "        fn = lambda N, gamma, delta, nu_max : integrateOut(p_nu(nu,gamma,delta,nu_max)*poisson_spikes(nu,N,T_total),nu)(N,gamma,delta,nu_max), \n",
    "        sequences=[N_AP],\n",
    "        non_sequences=[gamma,delta,nu_max],\n",
    "    )\n",
    "    \n",
    "    return p_N_AP_arr\n",
    "\n",
    "theano.gradient.verify_grad(p_N_AP_fun,[[0.,3.,5.],1.5,4.8,30.],rng=rng,mode='DebugMode')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be1063c5",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "p_N_AP = integrateOut(p_nu(nu,gamma,delta,nu_max)*poisson_spikes(nu,N,T_total),nu)(N,gamma,delta,nu_max)\n",
    "func_p = theano.function([N_AP,gamma,delta,nu_max],p_N_AP)\n",
    "func_vals = func_p([0,3,5,10],1.2,4.8,30.)\n",
    "print(func_vals)\n",
    "\n",
    "\n",
    "pGrad = T.jacobian(p_N_AP,[gamma,delta,nu_max],consider_constant=[N])\n",
    "funcGrad = theano.function([N,gamma,delta,nu_max],pGrad) ### somehow in here, copies are made, which dont fit ..\n",
    "grad_vals = funcGrad(0,1.2,4.8,30.)\n",
    "print(grad_vals)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 239,
   "id": "7eddd7fb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[make node (fun)]: inputs: (N, gamma, delta, nu_max), fvars:[N, gamma, delta, nu_max]\n",
      "calc grad with inputs [N, gamma, delta, nu_max]\n",
      "gradF: [Elemwise{add,no_inplace}.0, Elemwise{add,no_inplace}.0, Elemwise{add,no_inplace}.0, Elemwise{add,no_inplace}.0]\n",
      "[make node (fun)]: inputs: (N, gamma, delta, nu_max), fvars:[N, gamma, delta, nu_max]\n",
      "[make node (fun)]: inputs: (N, gamma, delta, nu_max), fvars:[N, gamma, delta, nu_max]\n",
      "[make node (fun)]: inputs: (N, gamma, delta, nu_max), fvars:[N, gamma, delta, nu_max]\n",
      "[make node (fun)]: inputs: (N, gamma, delta, nu_max), fvars:[N, gamma, delta, nu_max]\n",
      "[perform (fun)]: inputs: [array(0.), array(1.2), array(4.8), array(30.)], fvars:[N, gamma, delta, nu_max]\n",
      "(array(0.), array(1.2), array(4.8), array(30.))\n",
      "[perform (fun)]: inputs: [array(0.), array(1.2), array(4.8), array(30.)], fvars:[N, gamma, delta, nu_max]\n",
      "(array(0.), array(1.2), array(4.8), array(30.))\n",
      "[perform (fun)]: inputs: [array(0.), array(1.2), array(4.8), array(30.)], fvars:[N, gamma, delta, nu_max]\n",
      "(array(0.), array(1.2), array(4.8), array(30.))\n",
      "[array(2.3231358e-09), array(-3.89161108e-10), array(1.61908823e-12)]\n"
     ]
    }
   ],
   "source": [
    "p_N_AP = integrateOut(p_nu(nu,gamma,delta,nu_max)*poisson_spikes(nu,N,T_total),nu)(N,gamma,delta,nu_max)\n",
    "pGrad = T.jacobian(p_N_AP,[gamma,delta,nu_max],consider_constant=[N])\n",
    "funcGrad = theano.function([N,gamma,delta,nu_max],pGrad) ### somehow in here, copies are made, which dont fit ..\n",
    "grad_vals = funcGrad(0,1.2,4.8,30.)\n",
    "print(grad_vals)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98a2f570",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "inference",
   "language": "python",
   "name": "inference"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
