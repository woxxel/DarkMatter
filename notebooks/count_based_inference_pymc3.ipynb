{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e1152489",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import h5py\n",
    "import scipy.io as sio\n",
    "\n",
    "import os, sys\n",
    "root_dir = os.path.dirname(os.path.abspath(''))\n",
    "if not root_dir in sys.path: sys.path.append(root_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f6685d73",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pymc3 as pm\n",
    "import arviz as az\n",
    "import theano.tensor as tt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ea13c303",
   "metadata": {},
   "outputs": [],
   "source": [
    "from inference import *\n",
    "from DM_theory import *\n",
    "from empirical.readData import *\n",
    "from empirical.model import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e653a499",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "expanding @ lvl animal with keys: ['20180325 (app ko7 739)' '20180325A (app ko8 740)'\n",
      " '20180402A (app ko13 734)' '20180419 (app ko14 756)'], selectors: ('LM (APLP1 KO)',)\n",
      "expanding @ lvl animal with keys: ['20180310A' '20180310B' '20180312A' '20180401'], selectors: ('WT',)\n",
      "zeros in data: 1480\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/wollex/Data/Science/WolfGroup/DarkMatter/Programme/empirical/readData.py:176: PerformanceWarning: indexing past lexsort depth may impact performance.\n",
      "  keys = np.unique(list(data[selector].columns.get_level_values(this_level)))\n",
      "/home/wollex/Data/Science/WolfGroup/DarkMatter/Programme/empirical/readData.py:176: PerformanceWarning: indexing past lexsort depth may impact performance.\n",
      "  keys = np.unique(list(data[selector].columns.get_level_values(this_level)))\n"
     ]
    }
   ],
   "source": [
    "def run_inference(filePath='../../data/BuscheLab/2P_data.xlsx',tune=20000,draws=10000,include_silent=False,\n",
    "                 loadPath=None,savePath=None):\n",
    "    I = Inference()\n",
    "    I.load_data('empirical',filePath=filePath,include_silent=include_silent)\n",
    "    I.set_model('selfcon')\n",
    "    I.run_on_data(tune=tune,draws=draws,loadPath=loadPath)\n",
    "    return I\n",
    "\n",
    "I = run_inference(include_silent=True,loadPath='results_xls_trace.nc')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "ad342bbc",
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.stats import binom\n",
    "from scipy.integrate import quad\n",
    "\n",
    "import theano\n",
    "import theano.tensor as T\n",
    "from theano.graph.op import Op\n",
    "from theano.graph.basic import Apply\n",
    "\n",
    "class integrateOut(Op):\n",
    "    \"\"\"\n",
    "    Integrate out a variable from an expression, computing\n",
    "    the definite integral w.r.t. the variable specified\n",
    "    !!! Only implemented in this for scalars !!!\n",
    "\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    f : scalar\n",
    "        input 'function' to integrate\n",
    "    t : scalar\n",
    "        the variable to integrate out\n",
    "    t0: float\n",
    "        lower integration limit\n",
    "    tf: float\n",
    "        upper integration limit\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    scalar\n",
    "        a new scalar with the 't' integrated out\n",
    "\n",
    "    Notes\n",
    "    -----\n",
    "    \n",
    "    function taken from https://stackoverflow.com/questions/42678490/custom-theano-op-to-do-numerical-integration\n",
    "    \n",
    "    usage of this looks like:\n",
    "    x = T.dscalar('x')\n",
    "    y = T.dscalar('y')\n",
    "    t = T.dscalar('t')\n",
    "\n",
    "    z = (x**2 + y**2)*t\n",
    "\n",
    "    # integrate z w.r.t. t as a function of (x,y)\n",
    "    intZ = integrateOut(z,t,0.0,5.0)(x,y)\n",
    "    gradIntZ = T.grad(intZ,[x,y])\n",
    "\n",
    "    funcIntZ = theano.function([x,y],intZ)\n",
    "    funcGradIntZ = theano.function([x,y],gradIntZ)\n",
    "\n",
    "    \"\"\"\n",
    "    def __init__(self,f,t,t0,tf,*args,**kwargs):\n",
    "        super(integrateOut,self).__init__()\n",
    "        self.f = f\n",
    "        self.t = t\n",
    "        self.t0 = t0\n",
    "        self.tf = tf\n",
    "\n",
    "    def make_node(self,*inputs):\n",
    "        self.fvars=list(inputs)\n",
    "        # This will fail when taking the gradient... don't be concerned\n",
    "        try:\n",
    "            self.gradF = T.grad(self.f,self.fvars)\n",
    "        except:\n",
    "            self.gradF = None\n",
    "        return Apply(self,self.fvars,[T.dscalar().type()])\n",
    "\n",
    "    def perform(self,node, inputs, output_storage):\n",
    "        # Everything else is an argument to the quad function\n",
    "        args = tuple(inputs)\n",
    "        # create a function to evaluate the integral\n",
    "        f = theano.function([self.t]+self.fvars,self.f)\n",
    "        # actually compute the integral\n",
    "        output_storage[0][0] = quad(f,self.t0,self.tf,args=args)[0]\n",
    "\n",
    "    def grad(self,inputs,grads):\n",
    "        return [integrateOut(g,self.t,self.t0,self.tf)(*inputs)*grads[0] \\\n",
    "            for g in self.gradF]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "8de88b9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "from theano import pp\n",
    "\n",
    "class binomial(Op):\n",
    "\n",
    "    def __init__(self,N,k,*args,**kwargs):\n",
    "        super(binomial,self).__init__()\n",
    "        \n",
    "        self.N = N\n",
    "        self.k = k\n",
    "\n",
    "    def make_node(self,*inputs):\n",
    "        self.fvars=list(inputs)\n",
    "        # This will fail when taking the gradient... don't be concerned\n",
    "        #try:\n",
    "        #self.gradF = math.comb(self.N,self.k)#T.grad(self.f,self.fvars)\n",
    "        #except:\n",
    "        #    self.gradF = None\n",
    "        return Apply(self,self.fvars,[T.dscalar().type()])\n",
    "\n",
    "    def perform(self,node,inputs,output_storage):\n",
    "        # create a function to evaluate the integral\n",
    "        p = inputs[0]\n",
    "        \n",
    "        # actually compute the binomial\n",
    "        output_storage[0][0] = binom.pmf(self.k,self.N,p)\n",
    "        \n",
    "    def grad(self,inputs,grads):\n",
    "        p = inputs[0]\n",
    "        print(f'inputs: {inputs}')\n",
    "        print(f'grads: {grads}')\n",
    "        #return [math.comb(self.N,self.k) * p**(self.k-1)* (1-p)**(self.N-self.k-1)*(self.k-self.N*p) * f\n",
    "        #    for f in grads]\n",
    "        #return inputs\n",
    "        return [binomial(self.N,self.k)(p) * (self.k-self.N*p)/(p * (1-p)) * g\n",
    "               for g in grads]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "cf785fee",
   "metadata": {},
   "outputs": [],
   "source": [
    "def logp_fun(data,gamma,delta,nu_max):\n",
    "    \n",
    "    p_silent_distr = p_nu(nu,gamma,delta,nu_max)*np.exp(-nu*T_total)#*poisson(nu,N_AP,T_total)\n",
    "    p_silent = integrateOut(p_silent_distr,nu,0,10.)(gamma,delta,nu_max,T_total)#,N_AP,T_total)\n",
    "    \n",
    "    p_N_AP = binomial(N_total,10)(p_silent)\n",
    "    \n",
    "    \n",
    "    if type(data)==np.array:\n",
    "        data_silent = data==0\n",
    "        N_silent = data_silent.sum()\n",
    "        data = data[data_silent]\n",
    "\n",
    "        p_silent = integrate.quad(lambda nu : p_nu(nu,gamma,delta,nu_max)*np.exp(-nu*T),0,10)\n",
    "\n",
    "    scaled_NU = tt.log(data / nu_max)\n",
    "    return - tt.log( nu_max / gamma * tt.sqrt( -np.pi * scaled_NU ) ) - delta**2 / 2 + \\\n",
    "        ( gamma**2 - 1 ) * scaled_NU + \\\n",
    "        tt.log( tt.cosh( gamma * delta * tt.sqrt( -2 * scaled_NU ) ) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "99f3a43b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "name: gamma\n",
      "{'mu': 1.5, 'sigma': 1.0, 'sigma_animal': 1.0, 'prior': 'Normal'}\n",
      "prior animal (final) __str__ = [370  15]\n",
      "name: delta\n",
      "{'mu': 4.0, 'sigma': 2.0, 'sigma_animal': 1.0, 'prior': 'Normal'}\n",
      "prior animal (final) __str__ = [370  15]\n",
      "name: nu_max\n",
      "{'mu': 60.0, 'sigma': 20.0, 'sigma_animal': 5.0, 'prior': 'Normal'}\n",
      "prior animal (final) __str__ = [370  15]\n",
      "logP __str__ = [ 0.21456278  0.20072879  0.2143889  ... -3.56940472 -3.6462295\n",
      " -3.79297369]\n",
      "logP __str__ = [ 0.21456278  0.20072879  0.2143889  ... -3.56940472 -3.6462295\n",
      " -3.79297369]\n",
      "logP __str__ = [ 0.21456278  0.20072879  0.2143889  ... -3.56940472 -3.6462295\n",
      " -3.79297369]\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'trace' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Input \u001b[0;32mIn [7]\u001b[0m, in \u001b[0;36m<cell line: 3>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     29\u001b[0m logP \u001b[38;5;241m=\u001b[39m pm\u001b[38;5;241m.\u001b[39mDensityDist(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mlogP\u001b[39m\u001b[38;5;124m'\u001b[39m,likelihood,observed\u001b[38;5;241m=\u001b[39mdata_observed)\n\u001b[1;32m     31\u001b[0m \u001b[38;5;66;03m#trace = pm.sample(\u001b[39;00m\n\u001b[1;32m     32\u001b[0m \u001b[38;5;66;03m#    init='adapt_diag',\u001b[39;00m\n\u001b[1;32m     33\u001b[0m \u001b[38;5;66;03m#    step=pm.Metropolis(),\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     38\u001b[0m \u001b[38;5;66;03m#if savePath:\u001b[39;00m\n\u001b[1;32m     39\u001b[0m \u001b[38;5;66;03m#    trace.to_netcdf(savePath)\u001b[39;00m\n\u001b[0;32m---> 41\u001b[0m I\u001b[38;5;241m.\u001b[39mtrace \u001b[38;5;241m=\u001b[39m \u001b[43mtrace\u001b[49m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'trace' is not defined"
     ]
    }
   ],
   "source": [
    "data_observed = I.data[I.data_mask]\n",
    "#silent = tt.le(data_observed,1./600)\n",
    "with pm.Model() as model:\n",
    "    # replace normals with student-t distributions\n",
    "\n",
    "    priors = {}\n",
    "    for para in I.paras:\n",
    "        priors[para] = I.construct_model_hierarchical(para)\n",
    "        priors[para] = priors[para][I.data_mask]\n",
    "\n",
    "\n",
    "    def likelihood(data):\n",
    "\n",
    "        # introduce checks for consistency, etc\n",
    "        logP = logp_fun(data,**priors)\n",
    "\n",
    "        # penalize nan-entries (e.g. when log is negative, etc)\n",
    "        # logP_masked = tt.switch(tt.isnan(logP), 0, logP)\n",
    "        # logP = tt.switch(silent, logP-10., logP)\n",
    "        #min_val = tt.min(logP_masked)\n",
    "        #tt.printing.Print('logP minimum')(tt.min(logP_masked))\n",
    "        tt.printing.Print('logP')(logP)\n",
    "\n",
    "        #logP = tt.switch(tt.isnan(logP), min_val*2, logP)\n",
    "\n",
    "        return tt.sum(logP)\n",
    "\n",
    "    ## watch out: for some reason, NaNs in observed data are converted to 0s\n",
    "    logP = pm.DensityDist('logP',likelihood,observed=data_observed)\n",
    "\n",
    "    #trace = pm.sample(\n",
    "    #    init='adapt_diag',\n",
    "    #    step=pm.Metropolis(),\n",
    "    #    chains=4,draws=draws,tune=tune,\n",
    "    #    return_inferencedata=True,\n",
    "    #    **kwargs)\n",
    "\n",
    "    #if savePath:\n",
    "    #    trace.to_netcdf(savePath)\n",
    "\n",
    "    #I.trace = trace"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "227aaf69",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "inference-kernel",
   "language": "python",
   "name": "inference-kernel"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
